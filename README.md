# SparkLogsAnalyzer

This project demonstrates how easy it is to use Apache Spark for logs analysis.
Logs analysis is an ideal use case for Spark, as it's a very large data source
that most organizations have, but logs are often too expensive to persist
to a traditional SQL or other type of database where they could be easily
digested.  Instead, logs are often stored in files to disk which have been
traditionally slow and difficult to process.  Logs contain an incredibly
rich set of information that can be used for business and customer
intelligence, for building recommendation systems, for preventing fraud,
and much more.  We hope this project will show you to use Apache Spark on
your organization's production logs and fully harness the power of 
all that data.

This project will also appeal to those who want to learn Spark and 
learn better by example.  Those readers can browse the chapters, see
what features of the logs analyzer is similar to their use case, and 
refashion the code samples in this project for their needs.

###[Chapter 1: Introduction to Apache Spark](chapter1/README.md)

The Apache Spark library is introduced, including RDD's, transformation, 
and actions.  We'll also introduce Spark SQL and Spark Streaming.  By the
end of this chapter, a reader will know how to do queries with Apache Spark.

### **Chapter 2: Importing data into Spark**

This chapter includes examples for batch import of data into Spark, 
as well as importing data for Spark Streaming.

### **Chapter 3: Exporting data out of Spark**

[[TBW]]

### Chapter 4: Machine Learning with Spark

[[TBW]]


This project is a work in progress, so please excuse if some of the examples
or documentation isn't refined.  Or better yet, submit a pull request to
contribute!
